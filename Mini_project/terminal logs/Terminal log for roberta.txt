Terminal log for roberta 


python Advanced_models\train.py roberta_trained.th roberta --B=8 --lr=0.00001 --epochs=2
Got CUDA!
tokenizer_config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25.0/25.0 [00:00<?, ?B/s]
C:\Users\nourh\miniconda3\envs\mon_env\Lib\site-packages\huggingface_hub\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\nourh\.cache\huggingface\hub\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
vocab.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 899k/899k [00:00<00:00, 3.21MB/s]
merges.txt: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 2.60MB/s]
tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.36M/1.36M [00:00<00:00, 3.99MB/s]
config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 481/481 [00:00<?, ?B/s]
model.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 499M/499M [00:42<00:00, 11.6MB/s]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
current lr 1.00000e-05
C:\Users\nourh\miniconda3\envs\mon_env\Lib\site-packages\transformers\models\roberta\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:555.)
  attn_output = torch.nn.functional.scaled_dot_product_attention(
Epoch: [0][0/3125]      Loss 0.6824 (0.6824)    Accuracy 75.000 (75.000)
Epoch: [0][25/3125]     Loss 0.6828 (0.6991)    Accuracy 87.500 (50.962)
Epoch: [0][50/3125]     Loss 0.5439 (0.6884)    Accuracy 100.000 (53.676)
Epoch: [0][75/3125]     Loss 0.3146 (0.6051)    Accuracy 87.500 (63.487)
Epoch: [0][100/3125]    Loss 0.0982 (0.5264)    Accuracy 100.000 (70.297)
Epoch: [0][125/3125]    Loss 0.0569 (0.4726)    Accuracy 100.000 (74.306)
Epoch: [0][150/3125]    Loss 0.2551 (0.4320)    Accuracy 87.500 (77.070)
Epoch: [0][175/3125]    Loss 0.3514 (0.4087)    Accuracy 75.000 (78.764)
Epoch: [0][200/3125]    Loss 0.2385 (0.3831)    Accuracy 87.500 (80.597)
Epoch: [0][225/3125]    Loss 0.0923 (0.3725)    Accuracy 100.000 (81.527)
Epoch: [0][250/3125]    Loss 0.1501 (0.3529)    Accuracy 87.500 (82.669)
Epoch: [0][275/3125]    Loss 0.1315 (0.3433)    Accuracy 87.500 (83.243)
Epoch: [0][300/3125]    Loss 0.1927 (0.3386)    Accuracy 87.500 (83.721)
Epoch: [0][325/3125]    Loss 0.0268 (0.3263)    Accuracy 100.000 (84.471)
Epoch: [0][350/3125]    Loss 0.0384 (0.3139)    Accuracy 100.000 (85.150)
Epoch: [0][375/3125]    Loss 0.1219 (0.3039)    Accuracy 87.500 (85.838)
Epoch: [0][400/3125]    Loss 0.4005 (0.3019)    Accuracy 87.500 (86.191)
Epoch: [0][425/3125]    Loss 0.0132 (0.2928)    Accuracy 100.000 (86.649)
Epoch: [0][450/3125]    Loss 0.1648 (0.2872)    Accuracy 87.500 (87.001)
Epoch: [0][475/3125]    Loss 0.5587 (0.2829)    Accuracy 75.000 (87.237)
Epoch: [0][500/3125]    Loss 0.2278 (0.2831)    Accuracy 87.500 (87.325)
Epoch: [0][525/3125]    Loss 0.2194 (0.2765)    Accuracy 87.500 (87.690)
Epoch: [0][550/3125]    Loss 0.1572 (0.2733)    Accuracy 87.500 (87.908)
Epoch: [0][575/3125]    Loss 0.1771 (0.2675)    Accuracy 87.500 (88.216)
Epoch: [0][600/3125]    Loss 0.0458 (0.2644)    Accuracy 100.000 (88.436)
Epoch: [0][625/3125]    Loss 0.0277 (0.2639)    Accuracy 100.000 (88.518)
Epoch: [0][650/3125]    Loss 0.2869 (0.2616)    Accuracy 87.500 (88.671)
Epoch: [0][675/3125]    Loss 0.0280 (0.2587)    Accuracy 100.000 (88.813)
Epoch: [0][700/3125]    Loss 0.2094 (0.2575)    Accuracy 100.000 (88.855)
Epoch: [0][725/3125]    Loss 0.0421 (0.2545)    Accuracy 100.000 (89.050)
Epoch: [0][750/3125]    Loss 0.0847 (0.2508)    Accuracy 100.000 (89.231)
Epoch: [0][775/3125]    Loss 0.1852 (0.2487)    Accuracy 87.500 (89.288)
Epoch: [0][800/3125]    Loss 0.5685 (0.2463)    Accuracy 62.500 (89.435)
Epoch: [0][825/3125]    Loss 0.4767 (0.2457)    Accuracy 87.500 (89.528)
Epoch: [0][850/3125]    Loss 0.0683 (0.2432)    Accuracy 100.000 (89.718)
Epoch: [0][875/3125]    Loss 0.0456 (0.2419)    Accuracy 100.000 (89.769)
Epoch: [0][900/3125]    Loss 0.1724 (0.2411)    Accuracy 87.500 (89.775)
Epoch: [0][925/3125]    Loss 0.1616 (0.2393)    Accuracy 87.500 (89.916)
Epoch: [0][950/3125]    Loss 0.0730 (0.2378)    Accuracy 100.000 (90.037)
Epoch: [0][975/3125]    Loss 0.0876 (0.2365)    Accuracy 100.000 (90.151)
Epoch: [0][1000/3125]   Loss 0.1549 (0.2366)    Accuracy 100.000 (90.172)
Epoch: [0][1025/3125]   Loss 0.1806 (0.2337)    Accuracy 87.500 (90.339)
Epoch: [0][1050/3125]   Loss 0.7857 (0.2335)    Accuracy 75.000 (90.378)
Epoch: [0][1075/3125]   Loss 0.7090 (0.2329)    Accuracy 87.500 (90.439)
Epoch: [0][1100/3125]   Loss 0.0176 (0.2310)    Accuracy 100.000 (90.543)
Epoch: [0][1125/3125]   Loss 0.0347 (0.2287)    Accuracy 100.000 (90.619)
Epoch: [0][1150/3125]   Loss 0.0237 (0.2274)    Accuracy 100.000 (90.715)
Epoch: [0][1175/3125]   Loss 0.2456 (0.2263)    Accuracy 87.500 (90.774)
Epoch: [0][1200/3125]   Loss 0.3666 (0.2250)    Accuracy 87.500 (90.831)
Epoch: [0][1225/3125]   Loss 0.0440 (0.2247)    Accuracy 100.000 (90.854)
Epoch: [0][1250/3125]   Loss 0.7103 (0.2238)    Accuracy 75.000 (90.917)
Epoch: [0][1275/3125]   Loss 0.0381 (0.2236)    Accuracy 100.000 (90.948)
Epoch: [0][1300/3125]   Loss 0.0512 (0.2217)    Accuracy 100.000 (91.036)
Epoch: [0][1325/3125]   Loss 0.0103 (0.2195)    Accuracy 100.000 (91.110)
Epoch: [0][1350/3125]   Loss 0.5144 (0.2188)    Accuracy 75.000 (91.136)
Epoch: [0][1375/3125]   Loss 0.0727 (0.2175)    Accuracy 100.000 (91.206)
Epoch: [0][1400/3125]   Loss 0.0138 (0.2160)    Accuracy 100.000 (91.301)
Epoch: [0][1425/3125]   Loss 0.3909 (0.2146)    Accuracy 87.500 (91.357)
Epoch: [0][1450/3125]   Loss 0.0198 (0.2144)    Accuracy 100.000 (91.359)
Epoch: [0][1475/3125]   Loss 0.2183 (0.2132)    Accuracy 87.500 (91.396)
Epoch: [0][1500/3125]   Loss 0.0217 (0.2118)    Accuracy 100.000 (91.472)
Epoch: [0][1525/3125]   Loss 0.1508 (0.2114)    Accuracy 100.000 (91.506)
Epoch: [0][1550/3125]   Loss 0.1424 (0.2116)    Accuracy 87.500 (91.473)
Epoch: [0][1575/3125]   Loss 0.2113 (0.2104)    Accuracy 87.500 (91.513)
Epoch: [0][1600/3125]   Loss 0.2320 (0.2105)    Accuracy 87.500 (91.513)
Epoch: [0][1625/3125]   Loss 0.0189 (0.2095)    Accuracy 100.000 (91.567)
Epoch: [0][1650/3125]   Loss 0.0309 (0.2092)    Accuracy 100.000 (91.611)
Epoch: [0][1675/3125]   Loss 0.0647 (0.2092)    Accuracy 100.000 (91.624)
Epoch: [0][1700/3125]   Loss 0.1189 (0.2077)    Accuracy 87.500 (91.667)
Epoch: [0][1725/3125]   Loss 0.0272 (0.2084)    Accuracy 100.000 (91.657)
Epoch: [0][1750/3125]   Loss 0.0712 (0.2078)    Accuracy 100.000 (91.676)
Epoch: [0][1775/3125]   Loss 0.3378 (0.2070)    Accuracy 87.500 (91.730)
Epoch: [0][1800/3125]   Loss 0.0622 (0.2060)    Accuracy 100.000 (91.762)
Epoch: [0][1825/3125]   Loss 0.0063 (0.2053)    Accuracy 100.000 (91.785)
Epoch: [0][1850/3125]   Loss 0.1678 (0.2044)    Accuracy 87.500 (91.815)
Epoch: [0][1875/3125]   Loss 0.6872 (0.2040)    Accuracy 75.000 (91.838)
Epoch: [0][1900/3125]   Loss 0.0431 (0.2038)    Accuracy 100.000 (91.840)
Epoch: [0][1925/3125]   Loss 0.1699 (0.2029)    Accuracy 87.500 (91.868)
Epoch: [0][1950/3125]   Loss 0.0092 (0.2015)    Accuracy 100.000 (91.921)
Epoch: [0][1975/3125]   Loss 0.3484 (0.2013)    Accuracy 75.000 (91.909)
Epoch: [0][2000/3125]   Loss 0.1032 (0.2013)    Accuracy 100.000 (91.929)
Epoch: [0][2025/3125]   Loss 0.1365 (0.2004)    Accuracy 87.500 (91.985)
Epoch: [0][2050/3125]   Loss 0.0151 (0.2000)    Accuracy 100.000 (92.004)
Epoch: [0][2075/3125]   Loss 0.0193 (0.1999)    Accuracy 100.000 (92.004)
Epoch: [0][2100/3125]   Loss 0.0184 (0.1987)    Accuracy 100.000 (92.057)
Epoch: [0][2125/3125]   Loss 0.3178 (0.1984)    Accuracy 87.500 (92.068)
Epoch: [0][2150/3125]   Loss 0.0356 (0.1971)    Accuracy 100.000 (92.108)
Epoch: [0][2175/3125]   Loss 0.3232 (0.1975)    Accuracy 87.500 (92.107)
Epoch: [0][2200/3125]   Loss 0.0227 (0.1964)    Accuracy 100.000 (92.163)
Epoch: [0][2225/3125]   Loss 0.0058 (0.1950)    Accuracy 100.000 (92.217)
Epoch: [0][2250/3125]   Loss 0.0450 (0.1949)    Accuracy 100.000 (92.242)
Epoch: [0][2275/3125]   Loss 0.0776 (0.1944)    Accuracy 100.000 (92.251)
Epoch: [0][2300/3125]   Loss 1.1669 (0.1944)    Accuracy 62.500 (92.264)
Epoch: [0][2325/3125]   Loss 0.1872 (0.1943)    Accuracy 87.500 (92.272)
Epoch: [0][2350/3125]   Loss 0.0643 (0.1948)    Accuracy 100.000 (92.269)
Epoch: [0][2375/3125]   Loss 0.0204 (0.1940)    Accuracy 100.000 (92.309)
Epoch: [0][2400/3125]   Loss 0.5712 (0.1941)    Accuracy 87.500 (92.347)
Epoch: [0][2425/3125]   Loss 0.0661 (0.1934)    Accuracy 100.000 (92.379)
Epoch: [0][2450/3125]   Loss 0.1740 (0.1932)    Accuracy 100.000 (92.391)
Epoch: [0][2475/3125]   Loss 0.0460 (0.1930)    Accuracy 100.000 (92.407)
Epoch: [0][2500/3125]   Loss 0.0382 (0.1926)    Accuracy 100.000 (92.433)
Epoch: [0][2525/3125]   Loss 0.4779 (0.1922)    Accuracy 87.500 (92.458)
Epoch: [0][2550/3125]   Loss 0.0287 (0.1917)    Accuracy 100.000 (92.469)
Epoch: [0][2575/3125]   Loss 0.0481 (0.1919)    Accuracy 100.000 (92.469)
Epoch: [0][2600/3125]   Loss 0.1157 (0.1920)    Accuracy 87.500 (92.479)
Epoch: [0][2625/3125]   Loss 0.1442 (0.1922)    Accuracy 100.000 (92.455)
Epoch: [0][2650/3125]   Loss 0.0242 (0.1914)    Accuracy 100.000 (92.489)
Epoch: [0][2675/3125]   Loss 0.0376 (0.1910)    Accuracy 100.000 (92.503)
Epoch: [0][2700/3125]   Loss 0.1612 (0.1908)    Accuracy 87.500 (92.517)
Epoch: [0][2725/3125]   Loss 0.2973 (0.1902)    Accuracy 75.000 (92.530)
Epoch: [0][2750/3125]   Loss 0.0299 (0.1902)    Accuracy 100.000 (92.530)
Epoch: [0][2775/3125]   Loss 0.0629 (0.1897)    Accuracy 100.000 (92.561)
Epoch: [0][2800/3125]   Loss 0.0363 (0.1896)    Accuracy 100.000 (92.565)
Epoch: [0][2825/3125]   Loss 0.1653 (0.1900)    Accuracy 87.500 (92.556)
Epoch: [0][2850/3125]   Loss 0.4909 (0.1900)    Accuracy 87.500 (92.568)
Epoch: [0][2875/3125]   Loss 0.1124 (0.1902)    Accuracy 100.000 (92.563)
Epoch: [0][2900/3125]   Loss 0.1652 (0.1897)    Accuracy 87.500 (92.589)
Epoch: [0][2925/3125]   Loss 0.2311 (0.1897)    Accuracy 87.500 (92.588)
Epoch: [0][2950/3125]   Loss 0.2831 (0.1897)    Accuracy 75.000 (92.575)
Epoch: [0][2975/3125]   Loss 0.0889 (0.1898)    Accuracy 100.000 (92.566)
Epoch: [0][3000/3125]   Loss 0.0588 (0.1893)    Accuracy 100.000 (92.582)
Epoch: [0][3025/3125]   Loss 0.2264 (0.1890)    Accuracy 87.500 (92.606)
Epoch: [0][3050/3125]   Loss 0.0178 (0.1886)    Accuracy 100.000 (92.621)
Epoch: [0][3075/3125]   Loss 0.0486 (0.1887)    Accuracy 100.000 (92.616)
Epoch: [0][3100/3125]   Loss 0.2617 (0.1887)    Accuracy 87.500 (92.611)

Test     Loss (0.1258)  Accuracy (95.500)

current lr 1.00000e-05
Epoch: [1][0/3125]      Loss 0.0125 (0.0125)    Accuracy 100.000 (100.000)
Epoch: [1][25/3125]     Loss 0.0961 (0.1008)    Accuracy 100.000 (96.154)
Epoch: [1][50/3125]     Loss 0.1281 (0.0889)    Accuracy 87.500 (97.059)
Epoch: [1][75/3125]     Loss 0.6271 (0.0942)    Accuracy 87.500 (97.039)
Epoch: [1][100/3125]    Loss 0.0855 (0.1002)    Accuracy 100.000 (96.782)
Epoch: [1][125/3125]    Loss 0.0544 (0.0964)    Accuracy 100.000 (96.825)
Epoch: [1][150/3125]    Loss 0.0221 (0.0952)    Accuracy 100.000 (96.854)
Epoch: [1][175/3125]    Loss 0.0082 (0.0988)    Accuracy 100.000 (96.591)
Epoch: [1][200/3125]    Loss 0.0071 (0.1029)    Accuracy 100.000 (96.269)
Epoch: [1][225/3125]    Loss 0.0136 (0.1043)    Accuracy 100.000 (96.350)
Epoch: [1][250/3125]    Loss 0.0092 (0.1061)    Accuracy 100.000 (96.215)
Epoch: [1][275/3125]    Loss 0.0331 (0.1063)    Accuracy 100.000 (96.196)
Epoch: [1][300/3125]    Loss 0.0838 (0.1031)    Accuracy 100.000 (96.346)
Epoch: [1][325/3125]    Loss 0.0241 (0.1015)    Accuracy 100.000 (96.357)
Epoch: [1][350/3125]    Loss 0.0339 (0.0976)    Accuracy 100.000 (96.510)
Epoch: [1][375/3125]    Loss 0.2880 (0.1010)    Accuracy 75.000 (96.343)
Epoch: [1][400/3125]    Loss 0.1124 (0.1018)    Accuracy 100.000 (96.322)
Epoch: [1][425/3125]    Loss 0.0045 (0.1068)    Accuracy 100.000 (96.156)
Epoch: [1][450/3125]    Loss 0.0230 (0.1052)    Accuracy 100.000 (96.258)
Epoch: [1][475/3125]    Loss 0.0316 (0.1058)    Accuracy 100.000 (96.192)
Epoch: [1][500/3125]    Loss 0.0446 (0.1036)    Accuracy 100.000 (96.233)
Epoch: [1][525/3125]    Loss 0.0118 (0.1030)    Accuracy 100.000 (96.269)
Epoch: [1][550/3125]    Loss 0.0779 (0.1085)    Accuracy 100.000 (96.053)
Epoch: [1][575/3125]    Loss 0.0807 (0.1080)    Accuracy 100.000 (96.115)
Epoch: [1][600/3125]    Loss 0.1875 (0.1086)    Accuracy 87.500 (96.131)
Epoch: [1][625/3125]    Loss 0.0846 (0.1085)    Accuracy 100.000 (96.106)
Epoch: [1][650/3125]    Loss 0.3620 (0.1087)    Accuracy 87.500 (96.083)
Epoch: [1][675/3125]    Loss 0.0737 (0.1085)    Accuracy 100.000 (96.080)
Epoch: [1][700/3125]    Loss 0.0070 (0.1083)    Accuracy 100.000 (96.059)
Epoch: [1][725/3125]    Loss 0.0396 (0.1083)    Accuracy 100.000 (96.040)
Epoch: [1][750/3125]    Loss 0.0394 (0.1085)    Accuracy 100.000 (96.039)
Epoch: [1][775/3125]    Loss 0.1753 (0.1081)    Accuracy 87.500 (96.053)
Epoch: [1][800/3125]    Loss 0.1628 (0.1088)    Accuracy 87.500 (96.067)
Epoch: [1][825/3125]    Loss 0.0083 (0.1084)    Accuracy 100.000 (96.065)
Epoch: [1][850/3125]    Loss 0.1183 (0.1102)    Accuracy 87.500 (96.019)
Epoch: [1][875/3125]    Loss 0.0185 (0.1108)    Accuracy 100.000 (95.947)
Epoch: [1][900/3125]    Loss 0.0804 (0.1138)    Accuracy 100.000 (95.838)
Epoch: [1][925/3125]    Loss 0.0210 (0.1145)    Accuracy 100.000 (95.815)
Epoch: [1][950/3125]    Loss 0.1466 (0.1157)    Accuracy 87.500 (95.794)
Epoch: [1][975/3125]    Loss 0.2026 (0.1159)    Accuracy 87.500 (95.799)
Epoch: [1][1000/3125]   Loss 0.0208 (0.1173)    Accuracy 100.000 (95.792)
Epoch: [1][1025/3125]   Loss 0.0144 (0.1165)    Accuracy 100.000 (95.833)
Epoch: [1][1050/3125]   Loss 0.0270 (0.1169)    Accuracy 100.000 (95.825)
Epoch: [1][1075/3125]   Loss 0.0152 (0.1162)    Accuracy 100.000 (95.864)
Epoch: [1][1100/3125]   Loss 0.0294 (0.1162)    Accuracy 100.000 (95.890)
Epoch: [1][1125/3125]   Loss 0.0110 (0.1166)    Accuracy 100.000 (95.926)
Epoch: [1][1150/3125]   Loss 0.2828 (0.1178)    Accuracy 87.500 (95.895)
Epoch: [1][1175/3125]   Loss 0.0195 (0.1170)    Accuracy 100.000 (95.918)
Epoch: [1][1200/3125]   Loss 0.0741 (0.1172)    Accuracy 100.000 (95.910)
Epoch: [1][1225/3125]   Loss 0.0352 (0.1159)    Accuracy 100.000 (95.962)
Epoch: [1][1250/3125]   Loss 0.0181 (0.1152)    Accuracy 100.000 (95.983)
Epoch: [1][1275/3125]   Loss 0.0053 (0.1158)    Accuracy 100.000 (95.954)
Epoch: [1][1300/3125]   Loss 0.0736 (0.1162)    Accuracy 100.000 (95.955)
Epoch: [1][1325/3125]   Loss 0.2862 (0.1162)    Accuracy 87.500 (95.956)
Epoch: [1][1350/3125]   Loss 0.0261 (0.1163)    Accuracy 100.000 (95.984)
Epoch: [1][1375/3125]   Loss 0.0688 (0.1155)    Accuracy 100.000 (96.012)
Epoch: [1][1400/3125]   Loss 0.0071 (0.1147)    Accuracy 100.000 (96.030)
Epoch: [1][1425/3125]   Loss 0.0998 (0.1158)    Accuracy 100.000 (95.985)
Epoch: [1][1450/3125]   Loss 0.0427 (0.1157)    Accuracy 100.000 (95.994)
Epoch: [1][1475/3125]   Loss 0.0167 (0.1165)    Accuracy 100.000 (95.986)
Epoch: [1][1500/3125]   Loss 0.0515 (0.1174)    Accuracy 100.000 (95.936)
Epoch: [1][1525/3125]   Loss 0.1541 (0.1172)    Accuracy 100.000 (95.962)
Epoch: [1][1550/3125]   Loss 0.0185 (0.1179)    Accuracy 100.000 (95.954)
Epoch: [1][1575/3125]   Loss 0.0133 (0.1176)    Accuracy 100.000 (95.963)
Epoch: [1][1600/3125]   Loss 0.1017 (0.1179)    Accuracy 100.000 (95.956)
Epoch: [1][1625/3125]   Loss 0.0119 (0.1175)    Accuracy 100.000 (95.964)
Epoch: [1][1650/3125]   Loss 0.1409 (0.1166)    Accuracy 87.500 (95.987)
Epoch: [1][1675/3125]   Loss 0.1079 (0.1163)    Accuracy 87.500 (95.987)
Epoch: [1][1700/3125]   Loss 0.0040 (0.1162)    Accuracy 100.000 (96.002)
Epoch: [1][1725/3125]   Loss 0.2757 (0.1164)    Accuracy 87.500 (95.988)
Epoch: [1][1750/3125]   Loss 0.0195 (0.1168)    Accuracy 100.000 (95.945)
Epoch: [1][1775/3125]   Loss 0.0264 (0.1179)    Accuracy 100.000 (95.911)
Epoch: [1][1800/3125]   Loss 0.1051 (0.1180)    Accuracy 100.000 (95.905)
Epoch: [1][1825/3125]   Loss 0.0356 (0.1179)    Accuracy 100.000 (95.920)
Epoch: [1][1850/3125]   Loss 0.0093 (0.1172)    Accuracy 100.000 (95.928)
Epoch: [1][1875/3125]   Loss 0.1987 (0.1174)    Accuracy 87.500 (95.916)
Epoch: [1][1900/3125]   Loss 0.0362 (0.1173)    Accuracy 100.000 (95.917)
Epoch: [1][1925/3125]   Loss 0.0193 (0.1175)    Accuracy 100.000 (95.918)
Epoch: [1][1950/3125]   Loss 0.4412 (0.1176)    Accuracy 75.000 (95.912)
Epoch: [1][1975/3125]   Loss 0.0085 (0.1172)    Accuracy 100.000 (95.932)
Epoch: [1][2000/3125]   Loss 0.0059 (0.1177)    Accuracy 100.000 (95.927)
Epoch: [1][2025/3125]   Loss 0.1794 (0.1174)    Accuracy 87.500 (95.934)
Epoch: [1][2050/3125]   Loss 0.0397 (0.1172)    Accuracy 100.000 (95.929)
Epoch: [1][2075/3125]   Loss 0.0263 (0.1164)    Accuracy 100.000 (95.948)
Epoch: [1][2100/3125]   Loss 0.3724 (0.1160)    Accuracy 87.500 (95.972)
Epoch: [1][2125/3125]   Loss 0.0295 (0.1163)    Accuracy 100.000 (95.949)
Epoch: [1][2150/3125]   Loss 0.6551 (0.1159)    Accuracy 75.000 (95.955)
Epoch: [1][2175/3125]   Loss 0.0559 (0.1158)    Accuracy 100.000 (95.962)
Epoch: [1][2200/3125]   Loss 0.1162 (0.1159)    Accuracy 87.500 (95.939)
Epoch: [1][2225/3125]   Loss 0.6600 (0.1163)    Accuracy 87.500 (95.912)
Epoch: [1][2250/3125]   Loss 0.1351 (0.1158)    Accuracy 87.500 (95.935)
Epoch: [1][2275/3125]   Loss 0.0122 (0.1156)    Accuracy 100.000 (95.936)
Epoch: [1][2300/3125]   Loss 0.0066 (0.1152)    Accuracy 100.000 (95.958)
Epoch: [1][2325/3125]   Loss 0.0235 (0.1152)    Accuracy 100.000 (95.953)
Epoch: [1][2350/3125]   Loss 0.0052 (0.1144)    Accuracy 100.000 (95.991)
Epoch: [1][2375/3125]   Loss 0.1545 (0.1151)    Accuracy 87.500 (95.981)
Epoch: [1][2400/3125]   Loss 0.6659 (0.1151)    Accuracy 87.500 (95.991)
Epoch: [1][2425/3125]   Loss 0.0258 (0.1154)    Accuracy 100.000 (95.986)
Epoch: [1][2450/3125]   Loss 0.0165 (0.1152)    Accuracy 100.000 (95.981)
Epoch: [1][2475/3125]   Loss 0.0055 (0.1151)    Accuracy 100.000 (95.992)
Epoch: [1][2500/3125]   Loss 0.0324 (0.1152)    Accuracy 100.000 (95.987)
Epoch: [1][2525/3125]   Loss 0.4169 (0.1151)    Accuracy 87.500 (95.987)
Epoch: [1][2550/3125]   Loss 0.0120 (0.1149)    Accuracy 100.000 (95.992)
Epoch: [1][2575/3125]   Loss 0.0312 (0.1151)    Accuracy 100.000 (95.982)
Epoch: [1][2600/3125]   Loss 0.0879 (0.1155)    Accuracy 100.000 (95.968)
Epoch: [1][2625/3125]   Loss 0.0076 (0.1151)    Accuracy 100.000 (95.982)
Epoch: [1][2650/3125]   Loss 0.0386 (0.1147)    Accuracy 100.000 (95.997)
Epoch: [1][2675/3125]   Loss 0.0029 (0.1145)    Accuracy 100.000 (95.997)
Epoch: [1][2700/3125]   Loss 0.0121 (0.1146)    Accuracy 100.000 (95.997)
Epoch: [1][2725/3125]   Loss 0.0785 (0.1143)    Accuracy 100.000 (96.011)
Epoch: [1][2750/3125]   Loss 0.3790 (0.1144)    Accuracy 87.500 (96.006)
Epoch: [1][2775/3125]   Loss 0.0081 (0.1140)    Accuracy 100.000 (96.019)
Epoch: [1][2800/3125]   Loss 0.2269 (0.1139)    Accuracy 87.500 (96.015)
Epoch: [1][2825/3125]   Loss 0.1567 (0.1140)    Accuracy 87.500 (95.997)
Epoch: [1][2850/3125]   Loss 0.0588 (0.1142)    Accuracy 100.000 (95.984)
Epoch: [1][2875/3125]   Loss 0.0074 (0.1141)    Accuracy 100.000 (95.988)
Epoch: [1][2900/3125]   Loss 0.2408 (0.1139)    Accuracy 87.500 (96.001)
Epoch: [1][2925/3125]   Loss 0.2407 (0.1137)    Accuracy 87.500 (96.010)
Epoch: [1][2950/3125]   Loss 0.0312 (0.1134)    Accuracy 100.000 (96.014)
Epoch: [1][2975/3125]   Loss 0.0697 (0.1133)    Accuracy 100.000 (96.010)
Epoch: [1][3000/3125]   Loss 0.0423 (0.1129)    Accuracy 100.000 (96.035)
Epoch: [1][3025/3125]   Loss 0.0068 (0.1124)    Accuracy 100.000 (96.055)
Epoch: [1][3050/3125]   Loss 0.0913 (0.1126)    Accuracy 100.000 (96.063)
Epoch: [1][3075/3125]   Loss 0.0054 (0.1125)    Accuracy 100.000 (96.066)
Epoch: [1][3100/3125]   Loss 0.2970 (0.1123)    Accuracy 87.500 (96.078)
Test     Loss (0.1256)  Accuracy (95.440)



